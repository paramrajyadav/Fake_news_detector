{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20795</th>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20796</th>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>Benjamin Hoffman</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20797</th>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20798</th>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2          2                  Why the Truth Might Get You Fired   \n",
       "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4          4  Iranian woman jailed for fictional unpublished...   \n",
       "...      ...                                                ...   \n",
       "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "20799  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                  Darrell Lucus   \n",
       "1                                Daniel J. Flynn   \n",
       "2                             Consortiumnews.com   \n",
       "3                                Jessica Purkiss   \n",
       "4                                 Howard Portnoy   \n",
       "...                                          ...   \n",
       "20795                              Jerome Hudson   \n",
       "20796                           Benjamin Hoffman   \n",
       "20797  Michael J. de la Merced and Rachel Abrams   \n",
       "20798                                Alex Ansary   \n",
       "20799                              David Swanson   \n",
       "\n",
       "                                                    text  label  \n",
       "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1      Ever get the feeling your life circles the rou...      0  \n",
       "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "...                                                  ...    ...  \n",
       "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "20796  When the Green Bay Packers lost to the Washing...      0  \n",
       "20797  The Macy’s of today grew from the union of sev...      0  \n",
       "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "20799    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[20800 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18285 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      18285 non-null  int64 \n",
      " 1   title   18285 non-null  object\n",
      " 2   author  18285 non-null  object\n",
      " 3   text    18285 non-null  object\n",
      " 4   label   18285 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 857.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             5\n",
      "title        456\n",
      "author       158\n",
      "text      142961\n",
      "label          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "max_lengths = df.apply(lambda col: col.astype(str).apply(len).max())\n",
    "\n",
    "# Print or use the max_lengths as needed\n",
    "print(max_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jackie Mason: Hollywood Would Love Trump if He Bombed North Korea over Lack of Trans Bathrooms (Exclusive Video) - Breitbart'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"title\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"id\",\"text\",\"author\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stopword = set(stopwords.words('english'))\n",
    "        self.data = None\n",
    "        self.data2 = None\n",
    "\n",
    "    def text_preproceesing_train(self,data1):\n",
    "        self.data=data1\n",
    "        lm=WordNetLemmatizer()\n",
    "        corpus=[]\n",
    "        for i in range(len(df)):\n",
    "            review=re.sub(r'^\\w*$',\" \",self.data[\"title\"][i] )\n",
    "            review=review.lower()\n",
    "            review=review.split()\n",
    "            review=[lm.lemmatize(x) for x in review if x not in stopword]\n",
    "            review=\" \".join(review)\n",
    "            \n",
    "            corpus.append(review)\n",
    "        return corpus\n",
    "    def text_preproceesing_pred(self,data2):\n",
    "        self.data2=data2\n",
    "        lm=WordNetLemmatizer()\n",
    "        processed=[]\n",
    "        for i in range(len(df)):\n",
    "            review=re.sub(r'^\\w*$',\" \",self.data2 )\n",
    "            review=review.lower()\n",
    "            review=review.split()\n",
    "            review=[lm.lemmatize(x) for x in review if x not in stopword]\n",
    "            review=\" \".join(review)\n",
    "            \n",
    "            processed.append(review)\n",
    "        return processed\n",
    "    def corpus_gen(self):\n",
    "        t1=self.text_preproceesing_train(self.data)\n",
    "        tf=TfidfVectorizer()\n",
    "        x=tf.fit_transform(t1).toarray()\n",
    "        y=self.data['label']\n",
    "        return x,y\n",
    "    \n",
    "    def corpus_pred(self):\n",
    "        t2=self.text_preproceesing_pred(self.data2)\n",
    "        tf=TfidfVectorizer()\n",
    "        x=tf.transform(t2).toarray()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\awscl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create a set of stopwords\n",
    "stopword = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc1=preprocessing()\n",
    "p2=proc1.text_preproceesing_train(df)\n",
    "x, y = proc1.corpus_gen()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "18280    0\n",
       "18281    0\n",
       "18282    0\n",
       "18283    1\n",
       "18284    1\n",
       "Name: label, Length: 18285, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=34, stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_gen():\n",
    "    def  __init__(self,x_train,x_test,y_train,y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test= x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test=y_test\n",
    "        self.model = None  \n",
    "\n",
    "    def model_build(self):\n",
    "        rf=RandomForestClassifier()\n",
    "        self.model = rf  # Store the model instance\n",
    "        self.model.fit(self.x_train, self.y_train)\n",
    "\n",
    "    # def train_evaluation(self):\n",
    "    #     y_pred_train = self.model.predict(self.x_train)\n",
    "        \n",
    "    #     acc_scr_train = (self.y_train.astype(int), y_pred_train.astype(int))\n",
    "    #     print(\"Accuracy Score On Training Data Set :\",acc_scr_train)\n",
    "    #     print()\n",
    "        \n",
    "    #     con_mat_train = confusion_matrix(self.y_train,y_pred_train)\n",
    "    #     print(\"Confusion Matrix On Training Data Set :\\n\",con_mat_train)\n",
    "    #     print()\n",
    "        \n",
    "    #     class_rep_train = classification_report(self.y_train,y_pred_train)\n",
    "    #     print(\"Classification Report On Training Data Set :\\n\",class_rep_train)\n",
    "        \n",
    "    # def test_evaluation(self):\n",
    "    #     y_pred_test = self.model.predict(self.x_test)\n",
    "        \n",
    "    #     acc_scr_test = accuracy_score(self.y_test,y_pred_test)\n",
    "    #     print(\"Accuracy Score On Testing Data Set :\",acc_scr_train)\n",
    "    #     print()\n",
    "        \n",
    "    #     con_mat_test = confusion_matrix(self.y_test,y_pred_test)\n",
    "    #     print(\"Confusion Matrix On Testing Data Set :\\n\",con_mat_train)\n",
    "    #     print()\n",
    "        \n",
    "    #     class_rep_test = classification_report(self.y_test,y_pred_test)\n",
    "    #     print(\"Classification Report On Testing Data Set :\\n\",class_rep_train)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=model_gen(x_train,x_test,y_train,y_test)\n",
    "m1.model_build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    def __init__(self, parent_instance):\n",
    "        self.parent_instance = parent_instance\n",
    "\n",
    "    def train_evaluation(self):\n",
    "        y_pred_train = self.parent_instance.model.predict(self.parent_instance.x_train)\n",
    "\n",
    "        acc_scr_train = accuracy_score(self.parent_instance.y_train, y_pred_train)\n",
    "        print(\"Custom Accuracy Score On Training Data Set :\", acc_scr_train)\n",
    "        print()\n",
    "\n",
    "        con_mat_train = confusion_matrix(self.parent_instance.y_train, y_pred_train)\n",
    "        print(\"Custom Confusion Matrix On Training Data Set :\\n\", con_mat_train)\n",
    "        print()\n",
    "\n",
    "        class_rep_train = classification_report(self.parent_instance.y_train, y_pred_train)\n",
    "        print(\"Custom Classification Report On Training Data Set :\\n\", class_rep_train)\n",
    "\n",
    "    def test_evaluation(self):\n",
    "        y_pred_test = self.parent_instance.model.predict(self.parent_instance.x_test)\n",
    "\n",
    "        acc_scr_test = accuracy_score(self.parent_instance.y_test, y_pred_test)\n",
    "        print(\"Custom Accuracy Score On Testing Data Set :\", acc_scr_test)\n",
    "        print()\n",
    "\n",
    "        con_mat_test = confusion_matrix(self.parent_instance.y_test, y_pred_test)\n",
    "        print(\"Custom Confusion Matrix On Testing Data Set :\\n\", con_mat_test)\n",
    "        print()\n",
    "\n",
    "        class_rep_test = classification_report(self.parent_instance.y_test, y_pred_test)\n",
    "        print(\"Custom Classification Report On Testing Data Set :\\n\", class_rep_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Accuracy Score On Training Data Set : 0.9999218688960075\n",
      "\n",
      "Custom Confusion Matrix On Training Data Set :\n",
      " [[7251    1]\n",
      " [   0 5547]]\n",
      "\n",
      "Custom Classification Report On Training Data Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7252\n",
      "           1       1.00      1.00      1.00      5547\n",
      "\n",
      "    accuracy                           1.00     12799\n",
      "   macro avg       1.00      1.00      1.00     12799\n",
      "weighted avg       1.00      1.00      1.00     12799\n",
      "\n",
      "Custom Accuracy Score On Testing Data Set : 0.9360189573459715\n",
      "\n",
      "Custom Confusion Matrix On Testing Data Set :\n",
      " [[2809  300]\n",
      " [  51 2326]]\n",
      "\n",
      "Custom Classification Report On Testing Data Set :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3109\n",
      "           1       0.89      0.98      0.93      2377\n",
      "\n",
      "    accuracy                           0.94      5486\n",
      "   macro avg       0.93      0.94      0.94      5486\n",
      "weighted avg       0.94      0.94      0.94      5486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m2 = CustomModel(m1)\n",
    "m2.train_evaluation()\n",
    "m2.test_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
